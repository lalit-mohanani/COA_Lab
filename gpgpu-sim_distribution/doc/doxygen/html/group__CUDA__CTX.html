<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>GPGPU-Sim: Context Management</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">GPGPU-Sim
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Context Management</div>  </div>
</div><!--header-->
<div class="contents">

<p>___MANBRIEF___ context management functions of the low-level CUDA driver API (___CURRENT_FILE___) ___ENDMANBRIEF___  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga37d9aab8410a94abcfa60a8f19a9d48f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f">cuCtxCreate</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *pctx, unsigned <a class="el" href="classint.html">int</a> flags, <a class="el" href="group__CUDA__TYPES.html#gacd81b70eb9968392bb5cdf582af8eab4">CUdevice</a> dev)</td></tr>
<tr class="memdesc:ga37d9aab8410a94abcfa60a8f19a9d48f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a CUDA context.  <a href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f">More...</a><br /></td></tr>
<tr class="separator:ga37d9aab8410a94abcfa60a8f19a9d48f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga371ec2a7d64ebe39e198eeb0b1146c4e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e">cuCtxDestroy</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> ctx)</td></tr>
<tr class="memdesc:ga371ec2a7d64ebe39e198eeb0b1146c4e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy a CUDA context.  <a href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e">More...</a><br /></td></tr>
<tr class="separator:ga371ec2a7d64ebe39e198eeb0b1146c4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8e80640a19cf279cd06df1022f12877d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d">cuCtxPushCurrent</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> ctx)</td></tr>
<tr class="memdesc:ga8e80640a19cf279cd06df1022f12877d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pushes a context on the current CPU thread.  <a href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d">More...</a><br /></td></tr>
<tr class="separator:ga8e80640a19cf279cd06df1022f12877d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab98ae0f3b858744645de0be934c12196"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196">cuCtxPopCurrent</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *pctx)</td></tr>
<tr class="memdesc:gab98ae0f3b858744645de0be934c12196"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pops the current CUDA context from the current CPU thread.  <a href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196">More...</a><br /></td></tr>
<tr class="separator:gab98ae0f3b858744645de0be934c12196"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf99108a1d0cb2e1f4b410a92f64323f8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gaf99108a1d0cb2e1f4b410a92f64323f8">cuCtxSetCurrent</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> ctx)</td></tr>
<tr class="memdesc:gaf99108a1d0cb2e1f4b410a92f64323f8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Binds the specified CUDA context to the calling CPU thread.  <a href="group__CUDA__CTX.html#gaf99108a1d0cb2e1f4b410a92f64323f8">More...</a><br /></td></tr>
<tr class="separator:gaf99108a1d0cb2e1f4b410a92f64323f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3d7eb010d6bc88939b4bb8914bc79053"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga3d7eb010d6bc88939b4bb8914bc79053">cuCtxGetCurrent</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *pctx)</td></tr>
<tr class="memdesc:ga3d7eb010d6bc88939b4bb8914bc79053"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the CUDA context bound to the calling CPU thread.  <a href="group__CUDA__CTX.html#ga3d7eb010d6bc88939b4bb8914bc79053">More...</a><br /></td></tr>
<tr class="separator:ga3d7eb010d6bc88939b4bb8914bc79053"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafe15c5d23b83550e31858899b081b4c3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3">cuCtxGetDevice</a> (<a class="el" href="group__CUDA__TYPES.html#gacd81b70eb9968392bb5cdf582af8eab4">CUdevice</a> *device)</td></tr>
<tr class="memdesc:gafe15c5d23b83550e31858899b081b4c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the device ID for the current context.  <a href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3">More...</a><br /></td></tr>
<tr class="separator:gafe15c5d23b83550e31858899b081b4c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga36193dc05dde46af588434abdc4f0714"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714">cuCtxGetFlags</a> (unsigned <a class="el" href="classint.html">int</a> *flags)</td></tr>
<tr class="memdesc:ga36193dc05dde46af588434abdc4f0714"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the flags for the current context.  <a href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714">More...</a><br /></td></tr>
<tr class="separator:ga36193dc05dde46af588434abdc4f0714"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabe39e7dfd58b9b0863781d669920f4cb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb">cuCtxSynchronize</a> (void)</td></tr>
<tr class="memdesc:gabe39e7dfd58b9b0863781d669920f4cb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Block for a context's tasks to complete.  <a href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb">More...</a><br /></td></tr>
<tr class="separator:gabe39e7dfd58b9b0863781d669920f4cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4629158e32b781e675573ea7c2c4dd17"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17">cuCtxSetLimit</a> (<a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a> limit, size_t value)</td></tr>
<tr class="memdesc:ga4629158e32b781e675573ea7c2c4dd17"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set resource limits.  <a href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17">More...</a><br /></td></tr>
<tr class="separator:ga4629158e32b781e675573ea7c2c4dd17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaab10bd874e0bf40a2989443ad42ed428"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428">cuCtxGetLimit</a> (size_t *pvalue, <a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a> limit)</td></tr>
<tr class="memdesc:gaab10bd874e0bf40a2989443ad42ed428"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns resource limits.  <a href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428">More...</a><br /></td></tr>
<tr class="separator:gaab10bd874e0bf40a2989443ad42ed428"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab144ce4581a0bf7cd362659776534a84"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84">cuCtxGetCacheConfig</a> (<a class="el" href="group__CUDA__TYPES.html#ga1377c306458eb37eacb1d43eb7e5661a">CUfunc_cache</a> *pconfig)</td></tr>
<tr class="memdesc:gab144ce4581a0bf7cd362659776534a84"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the preferred cache configuration for the current context.  <a href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84">More...</a><br /></td></tr>
<tr class="separator:gab144ce4581a0bf7cd362659776534a84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga138e543965e8c57c652100a3a0fdecd9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9">cuCtxSetCacheConfig</a> (<a class="el" href="group__CUDA__TYPES.html#ga1377c306458eb37eacb1d43eb7e5661a">CUfunc_cache</a> config)</td></tr>
<tr class="memdesc:ga138e543965e8c57c652100a3a0fdecd9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the preferred cache configuration for the current context.  <a href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9">More...</a><br /></td></tr>
<tr class="separator:ga138e543965e8c57c652100a3a0fdecd9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad66bf769b0b98da4d917aa49c8438b7f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f">cuCtxGetSharedMemConfig</a> (<a class="el" href="group__CUDA__TYPES.html#ga90e97218e0f4ead1df3b9297f2b507c5">CUsharedconfig</a> *pConfig)</td></tr>
<tr class="memdesc:gad66bf769b0b98da4d917aa49c8438b7f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the current shared memory configuration for the current context.  <a href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f">More...</a><br /></td></tr>
<tr class="separator:gad66bf769b0b98da4d917aa49c8438b7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab94b06157868dc684d2d9faf48468d30"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gab94b06157868dc684d2d9faf48468d30">cuCtxSetSharedMemConfig</a> (<a class="el" href="group__CUDA__TYPES.html#ga90e97218e0f4ead1df3b9297f2b507c5">CUsharedconfig</a> config)</td></tr>
<tr class="memdesc:gab94b06157868dc684d2d9faf48468d30"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the shared memory configuration for the current context.  <a href="group__CUDA__CTX.html#gab94b06157868dc684d2d9faf48468d30">More...</a><br /></td></tr>
<tr class="separator:gab94b06157868dc684d2d9faf48468d30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaba93fa1c4a4f3da76d87704716a3d3c0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0">cuCtxGetApiVersion</a> (<a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> ctx, unsigned <a class="el" href="classint.html">int</a> *version)</td></tr>
<tr class="memdesc:gaba93fa1c4a4f3da76d87704716a3d3c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the context's API version.  <a href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0">More...</a><br /></td></tr>
<tr class="separator:gaba93fa1c4a4f3da76d87704716a3d3c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2bd8e0507a6b90beac97e496fadf852f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CUDA__CTX.html#ga2bd8e0507a6b90beac97e496fadf852f">cuCtxGetStreamPriorityRange</a> (<a class="el" href="classint.html">int</a> *leastPriority, <a class="el" href="classint.html">int</a> *greatestPriority)</td></tr>
<tr class="memdesc:ga2bd8e0507a6b90beac97e496fadf852f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns numerical values that correspond to the least and greatest stream priorities.  <a href="group__CUDA__CTX.html#ga2bd8e0507a6b90beac97e496fadf852f">More...</a><br /></td></tr>
<tr class="separator:ga2bd8e0507a6b90beac97e496fadf852f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>___MANBRIEF___ context management functions of the low-level CUDA driver API (___CURRENT_FILE___) ___ENDMANBRIEF___ </p>
<p>This section describes the context management functions of the low-level CUDA driver application programming interface.</p>
<p>Please note that some functions are described in <a class="el" href="group__CUDA__PRIMARY__CTX.html">Primary Context Management</a> section. </p>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga37d9aab8410a94abcfa60a8f19a9d48f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga37d9aab8410a94abcfa60a8f19a9d48f">&#9670;&nbsp;</a></span>cuCtxCreate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxCreate </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *&#160;</td>
          <td class="paramname"><em>pctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>flags</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gacd81b70eb9968392bb5cdf582af8eab4">CUdevice</a>&#160;</td>
          <td class="paramname"><em>dev</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a CUDA context. </p>
<dl class="section note"><dt>Note</dt><dd>In most cases it is recommended to use <a class="el" href="group__CUDA__PRIMARY__CTX.html#ga4e92bce186e1f54f845faab565467b3f" title="Retain the primary context on the GPU.">cuDevicePrimaryCtxRetain</a>.</dd></dl>
<p>Creates a new CUDA context and associates it with the calling thread. The <code>flags</code> parameter is described below. The context is created with a usage count of 1 and the caller of <a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate()</a> must call <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy()</a> when done using the context. If a context is already current to the thread, it is supplanted by the newly created context and may be restored by a subsequent call to <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent()</a>.</p>
<p>The three LSBs of the <code>flags</code> parameter can be used to control how the OS thread, which owns the CUDA context at the time of an API call, interacts with the OS scheduler when waiting for results from the GPU. Only one of the scheduling flags can be set when creating a context.</p>
<ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a331d3ed1e0b55597258bd58346603afc">CU_CTX_SCHED_SPIN</a>: Instruct CUDA to actively spin when waiting for results from the GPU. This can decrease latency when waiting for the GPU, but may lower the performance of CPU threads if they are performing work in parallel with the CUDA thread.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a4bc43364906d8dd5a7d7c8ad46ccc548">CU_CTX_SCHED_YIELD</a>: Instruct CUDA to yield its thread when waiting for results from the GPU. This can increase latency when waiting for the GPU, but can increase the performance of CPU threads performing work in parallel with the GPU.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a62aebfe6432ade3feb32f1a409027852">CU_CTX_SCHED_BLOCKING_SYNC</a>: Instruct CUDA to block the CPU thread on a synchronization primitive when waiting for the GPU to finish work.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6ab5bf395cc60a8cbded4c329ae9430b91">CU_CTX_BLOCKING_SYNC</a>: Instruct CUDA to block the CPU thread on a synchronization primitive when waiting for the GPU to finish work. <br  />
 <b>Deprecated:</b> This flag was deprecated as of CUDA 4.0 and was replaced with <a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a62aebfe6432ade3feb32f1a409027852">CU_CTX_SCHED_BLOCKING_SYNC</a>.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6ad75f4c24f8c35ef2ee9d0793badfd88c">CU_CTX_SCHED_AUTO</a>: The default value if the <code>flags</code> parameter is zero, uses a heuristic based on the number of active CUDA contexts in the process <em>C</em> and the number of logical processors in the system <em>P</em>. If <em>C</em> &gt; <em>P</em>, then CUDA will yield to other OS threads when waiting for the GPU (<a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a4bc43364906d8dd5a7d7c8ad46ccc548">CU_CTX_SCHED_YIELD</a>), otherwise CUDA will not yield while waiting for results and actively spin on the processor (<a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a331d3ed1e0b55597258bd58346603afc">CU_CTX_SCHED_SPIN</a>). Additionally, on Tegra devices, <a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6ad75f4c24f8c35ef2ee9d0793badfd88c">CU_CTX_SCHED_AUTO</a> uses a heuristic based on the power profile of the platform and may choose <a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a62aebfe6432ade3feb32f1a409027852">CU_CTX_SCHED_BLOCKING_SYNC</a> for low-powered devices.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a08c822db270f4322af6e6bb0a7786514">CU_CTX_MAP_HOST</a>: Instruct CUDA to support mapped pinned allocations. This flag must be set in order to allocate pinned host memory that is accessible to the GPU.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6ab5a83507c2a7e14d301621c40c343a81">CU_CTX_LMEM_RESIZE_TO_MAX</a>: Instruct CUDA to not reduce local memory after resizing local memory for a kernel. This can prevent thrashing by local memory allocations when launching many kernels with high local memory usage at the cost of potentially increased memory usage.</li>
</ul>
<p>Context creation will fail with <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaac5a6ab0245179d297f1fa56ed0097183">CUDA_ERROR_UNKNOWN</a> if the compute mode of the device is <a class="el" href="group__CUDA__TYPES.html#gga409cfd7e4863c34f8430757482886d75adb8a226241187db3b1f41999bb70eb47">CU_COMPUTEMODE_PROHIBITED</a>. The function <a class="el" href="group__CUDA__DEVICE.html#ga5a73f28b53203cd6097fc48d97ca4ead" title="Returns information about the device.">cuDeviceGetAttribute()</a> can be used with <a class="el" href="group__CUDA__TYPES.html#gga3b9f561d2a42733dde99b2cedcaa413aaf6669a29a6d42968047747cbfc501289">CU_DEVICE_ATTRIBUTE_COMPUTE_MODE</a> to determine the compute mode of the device. The <em>nvidia-smi</em> tool can be used to set the compute mode for * devices. Documentation for <em>nvidia-smi</em> can be obtained by passing a -h option to it.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pctx</td><td>- Returned context handle of the new context </td></tr>
    <tr><td class="paramname">flags</td><td>- Context creation flags </td></tr>
    <tr><td class="paramname">dev</td><td>- Device to create context on</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa6f047e7215788ca96c81af92a04bfb6c">CUDA_ERROR_INVALID_DEVICE</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa264c50688ed110e8476b591befe60c02">CUDA_ERROR_OUT_OF_MEMORY</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaac5a6ab0245179d297f1fa56ed0097183">CUDA_ERROR_UNKNOWN</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04251">4251</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga371ec2a7d64ebe39e198eeb0b1146c4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga371ec2a7d64ebe39e198eeb0b1146c4e">&#9670;&nbsp;</a></span>cuCtxDestroy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxDestroy </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a>&#160;</td>
          <td class="paramname"><em>ctx</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroy a CUDA context. </p>
<p>Destroys the CUDA context specified by <code>ctx</code>. The context <code>ctx</code> will be destroyed regardless of how many threads it is current to. It is the responsibility of the calling function to ensure that no API call issues using <code>ctx</code> while <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy()</a> is executing.</p>
<p>If <code>ctx</code> is current to the calling thread then <code>ctx</code> will also be popped from the current thread's context stack (as though <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent()</a> were called). If <code>ctx</code> is current to other threads, then <code>ctx</code> will remain current to those threads, and attempting to access <code>ctx</code> from those threads will result in the error <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaab27ac43f7ce8446f5c9636dd73fb2139">CUDA_ERROR_CONTEXT_IS_DESTROYED</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ctx</td><td>- Context to destroy</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l06129">6129</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gaba93fa1c4a4f3da76d87704716a3d3c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaba93fa1c4a4f3da76d87704716a3d3c0">&#9670;&nbsp;</a></span>cuCtxGetApiVersion()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetApiVersion </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a>&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned <a class="el" href="classint.html">int</a> *&#160;</td>
          <td class="paramname"><em>version</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the context's API version. </p>
<p>Returns a version number in <code>version</code> corresponding to the capabilities of the context (e.g. 3010 or 3020), which library developers can use to direct callers to a specific API version. If <code>ctx</code> is NULL, returns the API version used to create the currently bound context.</p>
<p>Note that new API versions are only introduced when context capabilities are changed that break binary compatibility, so the API version and driver version may be different. For example, it is valid for the API version to be 3020 while the driver version is 4020.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ctx</td><td>- Context to check </td></tr>
    <tr><td class="paramname">version</td><td>- Pointer to version</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaac5a6ab0245179d297f1fa56ed0097183">CUDA_ERROR_UNKNOWN</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04381">4381</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gab144ce4581a0bf7cd362659776534a84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab144ce4581a0bf7cd362659776534a84">&#9670;&nbsp;</a></span>cuCtxGetCacheConfig()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetCacheConfig </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga1377c306458eb37eacb1d43eb7e5661a">CUfunc_cache</a> *&#160;</td>
          <td class="paramname"><em>pconfig</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the preferred cache configuration for the current context. </p>
<p>On devices where the L1 cache and shared memory use the same hardware resources, this function returns through <code>pconfig</code> the preferred cache configuration for the current context. This is only a preference. The driver will use the requested configuration if possible, but it is free to choose a different configuration if required to execute functions.</p>
<p>This will return a <code>pconfig</code> of <a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a47d2f367dc3965c27ff748688229dc22">CU_FUNC_CACHE_PREFER_NONE</a> on devices where the size of the L1 cache and shared memory are fixed.</p>
<p>The supported cache configurations are:</p><ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a47d2f367dc3965c27ff748688229dc22">CU_FUNC_CACHE_PREFER_NONE</a>: no preference for shared memory or L1 (default)</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a712f43defb051d7985317bce426cccc8">CU_FUNC_CACHE_PREFER_SHARED</a>: prefer larger shared memory and smaller L1 cache</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4ab1e6c4e889e1a70ed5283172be08f6a5">CU_FUNC_CACHE_PREFER_L1</a>: prefer larger L1 cache and smaller shared memory</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a4434321280821d844a15b02e4d6c80a9">CU_FUNC_CACHE_PREFER_EQUAL</a>: prefer equal sized L1 cache and shared memory</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pconfig</td><td>- Returned cache configuration</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="group__CUDA__EXEC.html#ga628976ef9f537b98b7271f8680bd8aa0" title="Sets the preferred cache configuration for a device function.">cuFuncSetCacheConfig</a>, ::cudaDeviceGetCacheConfig </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04347">4347</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga3d7eb010d6bc88939b4bb8914bc79053"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3d7eb010d6bc88939b4bb8914bc79053">&#9670;&nbsp;</a></span>cuCtxGetCurrent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetCurrent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *&#160;</td>
          <td class="paramname"><em>pctx</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the CUDA context bound to the calling CPU thread. </p>
<p>Returns in <code>*pctx</code> the CUDA context bound to the calling CPU thread. If no context is bound to the calling CPU thread then <code>*pctx</code> is set to NULL and <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a> is returned.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pctx</td><td>- Returned context handle</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#gaf99108a1d0cb2e1f4b410a92f64323f8" title="Binds the specified CUDA context to the calling CPU thread.">cuCtxSetCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="cuda__runtime__api_8cc.html#a86da5bf3a4a45a7e165ac79130c3bc4d">cudaGetDevice</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04296">4296</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gafe15c5d23b83550e31858899b081b4c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafe15c5d23b83550e31858899b081b4c3">&#9670;&nbsp;</a></span>cuCtxGetDevice()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetDevice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gacd81b70eb9968392bb5cdf582af8eab4">CUdevice</a> *&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the device ID for the current context. </p>
<p>Returns in <code>*device</code> the ordinal of the current context's device.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device</td><td>- Returned device ID for the current context</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="cuda__runtime__api_8cc.html#a86da5bf3a4a45a7e165ac79130c3bc4d">cudaGetDevice</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04305">4305</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga36193dc05dde46af588434abdc4f0714"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga36193dc05dde46af588434abdc4f0714">&#9670;&nbsp;</a></span>cuCtxGetFlags()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetFlags </td>
          <td>(</td>
          <td class="paramtype">unsigned <a class="el" href="classint.html">int</a> *&#160;</td>
          <td class="paramname"><em>flags</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the flags for the current context. </p>
<p>Returns in <code>*flags</code> the flags of the current context. See <a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a> for flag values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">flags</td><td>- Pointer to store flags of current context</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga3d7eb010d6bc88939b4bb8914bc79053" title="Returns the CUDA context bound to the calling CPU thread.">cuCtxGetCurrent</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a> <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f" title="Returns the current shared memory configuration for the current context.">cuCtxGetSharedMemConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga2bd8e0507a6b90beac97e496fadf852f" title="Returns numerical values that correspond to the least and greatest stream priorities.">cuCtxGetStreamPriorityRange</a>, ::cudaGetDeviceFlags </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04314">4314</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gaab10bd874e0bf40a2989443ad42ed428"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaab10bd874e0bf40a2989443ad42ed428">&#9670;&nbsp;</a></span>cuCtxGetLimit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetLimit </td>
          <td>(</td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>pvalue</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a>&#160;</td>
          <td class="paramname"><em>limit</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns resource limits. </p>
<p>Returns in <code>*pvalue</code> the current size of <code>limit</code>. The supported <a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a> values are:</p><ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8aebe51e384a8b4b79459915bb1c31bc39">CU_LIMIT_STACK_SIZE</a>: stack size in bytes of each GPU thread.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a16f25aa2c37a06580ab533d8ae7db948">CU_LIMIT_PRINTF_FIFO_SIZE</a>: size in bytes of the FIFO used by the ::printf() device system call.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a86d01dbc431b04edd5d618257aaa246b">CU_LIMIT_MALLOC_HEAP_SIZE</a>: size in bytes of the heap used by the ::malloc() and ::free() device system calls.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a592fb752cc173ad7a2a4026a40e38079">CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH</a>: maximum grid depth at which a thread can issue the device runtime call <a class="el" href="cuda__runtime__api_8cc.html#ab10bcf7183e1f78e0f5cac0672e0e4a1">cudaDeviceSynchronize()</a> to wait on child grid launches to complete.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8af79d7134ee03d52c0d8b1aecda1ae446">CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT</a>: maximum number of outstanding device runtime launches that can be made from this context.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8ae75d95ea7dac6821de11d122d77f390b">CU_LIMIT_MAX_L2_FETCH_GRANULARITY</a>: L2 cache fetch granularity.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">limit</td><td>- Limit to query </td></tr>
    <tr><td class="paramname">pvalue</td><td>- Returned size of limit</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaad10e6e6ef4b01290d2202d43c3ca6821">CUDA_ERROR_UNSUPPORTED_LIMIT</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="cuda__runtime__api_8cc.html#a2403a57ba43c546442c4cb80c171956f">cudaDeviceGetLimit</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04339">4339</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gad66bf769b0b98da4d917aa49c8438b7f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad66bf769b0b98da4d917aa49c8438b7f">&#9670;&nbsp;</a></span>cuCtxGetSharedMemConfig()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetSharedMemConfig </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga90e97218e0f4ead1df3b9297f2b507c5">CUsharedconfig</a> *&#160;</td>
          <td class="paramname"><em>pConfig</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the current shared memory configuration for the current context. </p>
<p>This function will return in <code>pConfig</code> the current size of shared memory banks in the current context. On devices with configurable shared memory banks, <a class="el" href="group__CUDA__CTX.html#gab94b06157868dc684d2d9faf48468d30" title="Sets the shared memory configuration for the current context.">cuCtxSetSharedMemConfig</a> can be used to change this setting, so that all subsequent kernel launches will by default use the new bank size. When <a class="el" href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f" title="Returns the current shared memory configuration for the current context.">cuCtxGetSharedMemConfig</a> is called on devices without configurable shared memory, it will return the fixed bank size of the hardware.</p>
<p>The returned bank configurations can be either:</p><ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga27be7ddf29b2adb5678bb3972371cbf5a18d5d945c971d5d288d2693cbaa4d7dc">CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE</a>: shared memory bank width is four bytes.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga27be7ddf29b2adb5678bb3972371cbf5a081c400b814b9832b8a934ad2934985c">CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE</a>: shared memory bank width will eight bytes.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pConfig</td><td>- returned shared memory configuration </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f" title="Returns the current shared memory configuration for the current context.">cuCtxGetSharedMemConfig</a>, <a class="el" href="group__CUDA__EXEC.html#ga628976ef9f537b98b7271f8680bd8aa0" title="Sets the preferred cache configuration for a device function.">cuFuncSetCacheConfig</a>, ::cudaDeviceGetSharedMemConfig </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04364">4364</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga2bd8e0507a6b90beac97e496fadf852f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2bd8e0507a6b90beac97e496fadf852f">&#9670;&nbsp;</a></span>cuCtxGetStreamPriorityRange()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxGetStreamPriorityRange </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classint.html">int</a> *&#160;</td>
          <td class="paramname"><em>leastPriority</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classint.html">int</a> *&#160;</td>
          <td class="paramname"><em>greatestPriority</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns numerical values that correspond to the least and greatest stream priorities. </p>
<p>Returns in <code>*leastPriority</code> and <code>*greatestPriority</code> the numerical values that correspond to the least and greatest stream priorities respectively. Stream priorities follow a convention where lower numbers imply greater priorities. The range of meaningful stream priorities is given by [<code>*greatestPriority</code>, <code>*leastPriority</code>]. If the user attempts to create a stream with a priority value that is outside the meaningful range as specified by this API, the priority is automatically clamped down or up to either <code>*leastPriority</code> or <code>*greatestPriority</code> respectively. See <a class="el" href="group__CUDA__STREAM.html#gaea2fc94b2745094bf05cae5b1495de9a" title="Create a stream with the given priority.">cuStreamCreateWithPriority</a> for details on creating a priority stream. A NULL may be passed in for <code>*leastPriority</code> or <code>*greatestPriority</code> if the value is not desired.</p>
<p>This function will return '0' in both <code>*leastPriority</code> and <code>*greatestPriority</code> if the current context's device does not support stream priorities (see <a class="el" href="group__CUDA__DEVICE.html#ga5a73f28b53203cd6097fc48d97ca4ead" title="Returns information about the device.">cuDeviceGetAttribute</a>).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">leastPriority</td><td>- Pointer to an int in which the numerical value for least stream priority is returned</td></tr>
    <tr><td class="paramname">greatestPriority</td><td>- Pointer to an int in which the numerical value for greatest stream priority is returned</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__STREAM.html#gaea2fc94b2745094bf05cae5b1495de9a" title="Create a stream with the given priority.">cuStreamCreateWithPriority</a>, <a class="el" href="group__CUDA__STREAM.html#ga4c770598e9212421ce27d0715430c2b1" title="Query the priority of a given stream.">cuStreamGetPriority</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="cuda__runtime__api_8cc.html#a759ebce55d08057dceebf6063f69b1fd">cudaDeviceGetStreamPriorityRange</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04389">4389</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gab98ae0f3b858744645de0be934c12196"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab98ae0f3b858744645de0be934c12196">&#9670;&nbsp;</a></span>cuCtxPopCurrent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxPopCurrent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a> *&#160;</td>
          <td class="paramname"><em>pctx</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pops the current CUDA context from the current CPU thread. </p>
<p>Pops the current CUDA context from the CPU thread and passes back the old context handle in <code>*pctx</code>. That context may then be made current to a different CPU thread by calling <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent()</a>.</p>
<p>If a context was current to the CPU thread before <a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate()</a> or <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent()</a> was called, this function makes that context current to the CPU thread again.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pctx</td><td>- Returned new context handle</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l06136">6136</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga8e80640a19cf279cd06df1022f12877d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8e80640a19cf279cd06df1022f12877d">&#9670;&nbsp;</a></span>cuCtxPushCurrent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxPushCurrent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a>&#160;</td>
          <td class="paramname"><em>ctx</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pushes a context on the current CPU thread. </p>
<p>Pushes the given context <code>ctx</code> onto the CPU thread's stack of current contexts. The specified context becomes the CPU thread's current context, so all CUDA functions that operate on the current context are affected.</p>
<p>The previous current context may be made current again by calling <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy()</a> or <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent()</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ctx</td><td>- Context to push</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l06143">6143</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga138e543965e8c57c652100a3a0fdecd9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga138e543965e8c57c652100a3a0fdecd9">&#9670;&nbsp;</a></span>cuCtxSetCacheConfig()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxSetCacheConfig </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga1377c306458eb37eacb1d43eb7e5661a">CUfunc_cache</a>&#160;</td>
          <td class="paramname"><em>config</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the preferred cache configuration for the current context. </p>
<p>On devices where the L1 cache and shared memory use the same hardware resources, this sets through <code>config</code> the preferred cache configuration for the current context. This is only a preference. The driver will use the requested configuration if possible, but it is free to choose a different configuration if required to execute the function. Any function preference set via <a class="el" href="group__CUDA__EXEC.html#ga628976ef9f537b98b7271f8680bd8aa0" title="Sets the preferred cache configuration for a device function.">cuFuncSetCacheConfig()</a> will be preferred over this context-wide setting. Setting the context-wide cache configuration to <a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a47d2f367dc3965c27ff748688229dc22">CU_FUNC_CACHE_PREFER_NONE</a> will cause subsequent kernel launches to prefer to not change the cache configuration unless required to launch the kernel.</p>
<p>This setting does nothing on devices where the size of the L1 cache and shared memory are fixed.</p>
<p>Launching a kernel with a different preference than the most recent preference setting may insert a device-side synchronization point.</p>
<p>The supported cache configurations are:</p><ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a47d2f367dc3965c27ff748688229dc22">CU_FUNC_CACHE_PREFER_NONE</a>: no preference for shared memory or L1 (default)</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a712f43defb051d7985317bce426cccc8">CU_FUNC_CACHE_PREFER_SHARED</a>: prefer larger shared memory and smaller L1 cache</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4ab1e6c4e889e1a70ed5283172be08f6a5">CU_FUNC_CACHE_PREFER_L1</a>: prefer larger L1 cache and smaller shared memory</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga5d731dfd360f2a68ae45a4df46089af4a4434321280821d844a15b02e4d6c80a9">CU_FUNC_CACHE_PREFER_EQUAL</a>: prefer equal sized L1 cache and shared memory</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">config</td><td>- Requested cache configuration</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="group__CUDA__EXEC.html#ga628976ef9f537b98b7271f8680bd8aa0" title="Sets the preferred cache configuration for a device function.">cuFuncSetCacheConfig</a>, ::cudaDeviceSetCacheConfig </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04355">4355</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gaf99108a1d0cb2e1f4b410a92f64323f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf99108a1d0cb2e1f4b410a92f64323f8">&#9670;&nbsp;</a></span>cuCtxSetCurrent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxSetCurrent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#gaf9f5bd81658f866613785b3a0bb7d7d9">CUcontext</a>&#160;</td>
          <td class="paramname"><em>ctx</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Binds the specified CUDA context to the calling CPU thread. </p>
<p>Binds the specified CUDA context to the calling CPU thread. If <code>ctx</code> is NULL then the CUDA context previously bound to the calling CPU thread is unbound and <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a> is returned.</p>
<p>If there exists a CUDA context stack on the calling CPU thread, this will replace the top of that stack with <code>ctx</code>. If <code>ctx</code> is NULL then this will be equivalent to popping the top of the calling CPU thread's CUDA context stack (or a no-op if the calling CPU thread's CUDA context stack is empty).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ctx</td><td>- Context to bind to the calling CPU thread</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga3d7eb010d6bc88939b4bb8914bc79053" title="Returns the CUDA context bound to the calling CPU thread.">cuCtxGetCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="cuda__runtime__api_8cc.html#a7b63629909800b614427aae92b22d606">cudaSetDevice</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04288">4288</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="ga4629158e32b781e675573ea7c2c4dd17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4629158e32b781e675573ea7c2c4dd17">&#9670;&nbsp;</a></span>cuCtxSetLimit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxSetLimit </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a>&#160;</td>
          <td class="paramname"><em>limit</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>value</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set resource limits. </p>
<p>Setting <code>limit</code> to <code>value</code> is a request by the application to update the current limit maintained by the context. The driver is free to modify the requested value to meet h/w requirements (this could be clamping to minimum or maximum values, rounding up to nearest element size, etc). The application can use <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit()</a> to find out exactly what the limit has been set to.</p>
<p>Setting each <a class="el" href="group__CUDA__TYPES.html#ga97c12b669f01cd3285e2d52e3717c176">CUlimit</a> has its own specific restrictions, so each is discussed here.</p>
<ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8aebe51e384a8b4b79459915bb1c31bc39">CU_LIMIT_STACK_SIZE</a> controls the stack size in bytes of each GPU thread. Note that the CUDA driver will set the <code>limit</code> to the maximum of <code>value</code> and what the kernel function requires.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a16f25aa2c37a06580ab533d8ae7db948">CU_LIMIT_PRINTF_FIFO_SIZE</a> controls the size in bytes of the FIFO used by the ::printf() device system call. Setting <a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a16f25aa2c37a06580ab533d8ae7db948">CU_LIMIT_PRINTF_FIFO_SIZE</a> must be performed before launching any kernel that uses the ::printf() device system call, otherwise <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> will be returned.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a86d01dbc431b04edd5d618257aaa246b">CU_LIMIT_MALLOC_HEAP_SIZE</a> controls the size in bytes of the heap used by the ::malloc() and ::free() device system calls. Setting <a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a86d01dbc431b04edd5d618257aaa246b">CU_LIMIT_MALLOC_HEAP_SIZE</a> must be performed before launching any kernel that uses the ::malloc() or ::free() device system calls, otherwise <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> will be returned.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8a592fb752cc173ad7a2a4026a40e38079">CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH</a> controls the maximum nesting depth of a grid at which a thread can safely call <a class="el" href="cuda__runtime__api_8cc.html#ab10bcf7183e1f78e0f5cac0672e0e4a1">cudaDeviceSynchronize()</a>. Setting this limit must be performed before any launch of a kernel that uses the device runtime and calls <a class="el" href="cuda__runtime__api_8cc.html#ab10bcf7183e1f78e0f5cac0672e0e4a1">cudaDeviceSynchronize()</a> above the default sync depth, two levels of grids. Calls to <a class="el" href="cuda__runtime__api_8cc.html#ab10bcf7183e1f78e0f5cac0672e0e4a1">cudaDeviceSynchronize()</a> will fail with error code ::cudaErrorSyncDepthExceeded if the limitation is violated. This limit can be set smaller than the default or up the maximum launch depth of 24. When setting this limit, keep in mind that additional levels of sync depth require the driver to reserve large amounts of device memory which can no longer be used for user allocations. If these reservations of device memory fail, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a> will return <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa264c50688ed110e8476b591befe60c02">CUDA_ERROR_OUT_OF_MEMORY</a>, and the limit can be reset to a lower value. This limit is only applicable to devices of compute capability 3.5 and higher. Attempting to set this limit on devices of compute capability less than 3.5 will result in the error <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaad10e6e6ef4b01290d2202d43c3ca6821">CUDA_ERROR_UNSUPPORTED_LIMIT</a> being returned.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8af79d7134ee03d52c0d8b1aecda1ae446">CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT</a> controls the maximum number of outstanding device runtime launches that can be made from the current context. A grid is outstanding from the point of launch up until the grid is known to have been completed. Device runtime launches which violate this limitation fail and return ::cudaErrorLaunchPendingCountExceeded when <a class="el" href="cuda__runtime__api_8cc.html#ac28a3e711668eaf093350bade8ad4bc1">cudaGetLastError()</a> is called after launch. If more pending launches than the default (2048 launches) are needed for a module using the device runtime, this limit can be increased. Keep in mind that being able to sustain additional pending launches will require the driver to reserve larger amounts of device memory upfront which can no longer be used for allocations. If these reservations fail, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a> will return <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa264c50688ed110e8476b591befe60c02">CUDA_ERROR_OUT_OF_MEMORY</a>, and the limit can be reset to a lower value. This limit is only applicable to devices of compute capability 3.5 and higher. Attempting to set this limit on devices of compute capability less than 3.5 will result in the error <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaad10e6e6ef4b01290d2202d43c3ca6821">CUDA_ERROR_UNSUPPORTED_LIMIT</a> being returned.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga8054bb850a48a884875c90659d81bfd8ae75d95ea7dac6821de11d122d77f390b">CU_LIMIT_MAX_L2_FETCH_GRANULARITY</a> controls the L2 cache fetch granularity. Values can range from 0B to 128B. This is purely a performance hint and it can be ignored or clamped depending on the platform.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">limit</td><td>- Limit to set </td></tr>
    <tr><td class="paramname">value</td><td>- Size of limit</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaad10e6e6ef4b01290d2202d43c3ca6821">CUDA_ERROR_UNSUPPORTED_LIMIT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa264c50688ed110e8476b591befe60c02">CUDA_ERROR_OUT_OF_MEMORY</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="cuda__runtime__api_8cc.html#a2f463a1b29df6299944e0c1004a26f89">cudaDeviceSetLimit</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04331">4331</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gab94b06157868dc684d2d9faf48468d30"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab94b06157868dc684d2d9faf48468d30">&#9670;&nbsp;</a></span>cuCtxSetSharedMemConfig()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxSetSharedMemConfig </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CUDA__TYPES.html#ga90e97218e0f4ead1df3b9297f2b507c5">CUsharedconfig</a>&#160;</td>
          <td class="paramname"><em>config</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the shared memory configuration for the current context. </p>
<p>On devices with configurable shared memory banks, this function will set the context's shared memory bank size which is used for subsequent kernel launches.</p>
<p>Changed the shared memory configuration between launches may insert a device side synchronization point between those launches.</p>
<p>Changing the shared memory bank size will not increase shared memory usage or affect occupancy of kernels, but may have major effects on performance. Larger bank sizes will allow for greater potential bandwidth to shared memory, but will change what kinds of accesses to shared memory will result in bank conflicts.</p>
<p>This function will do nothing on devices with fixed shared memory bank size.</p>
<p>The supported bank configurations are:</p><ul>
<li><a class="el" href="group__CUDA__TYPES.html#gga27be7ddf29b2adb5678bb3972371cbf5ad65d166d885bd3f41bf1ced4ab8e044e">CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE</a>: set bank width to the default initial setting (currently, four bytes).</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga27be7ddf29b2adb5678bb3972371cbf5a18d5d945c971d5d288d2693cbaa4d7dc">CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE</a>: set shared memory bank width to be natively four bytes.</li>
<li><a class="el" href="group__CUDA__TYPES.html#gga27be7ddf29b2adb5678bb3972371cbf5a081c400b814b9832b8a934ad2934985c">CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE</a>: set shared memory bank width to be natively eight bytes.</li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">config</td><td>- requested shared memory configuration</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa90696c86fcee1f536a1ec7d25867feeb">CUDA_ERROR_INVALID_VALUE</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize</a>, <a class="el" href="group__CUDA__CTX.html#gad66bf769b0b98da4d917aa49c8438b7f" title="Returns the current shared memory configuration for the current context.">cuCtxGetSharedMemConfig</a>, <a class="el" href="group__CUDA__EXEC.html#ga628976ef9f537b98b7271f8680bd8aa0" title="Sets the preferred cache configuration for a device function.">cuFuncSetCacheConfig</a>, ::cudaDeviceSetSharedMemConfig </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04372">4372</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
<a id="gabe39e7dfd58b9b0863781d669920f4cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabe39e7dfd58b9b0863781d669920f4cb">&#9670;&nbsp;</a></span>cuCtxSynchronize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__CUDA__TYPES.html#gaf18c3affd9d913e337e3794abeade307">CUresult</a> CUDAAPI cuCtxSynchronize </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Block for a context's tasks to complete. </p>
<p>Blocks until the device has completed all preceding requested tasks. <a class="el" href="group__CUDA__CTX.html#gabe39e7dfd58b9b0863781d669920f4cb" title="Block for a context&#39;s tasks to complete.">cuCtxSynchronize()</a> returns an error if one of the preceding tasks failed. If the context was created with the <a class="el" href="group__CUDA__TYPES.html#gga12d89ce3fea2678bf187aa2876ed67a6a62aebfe6432ade3feb32f1a409027852">CU_CTX_SCHED_BLOCKING_SYNC</a> flag, the CPU thread will block until the GPU context has finished its work.</p>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa0eed720f8a87cd1c5fd1c453bc7a03d">CUDA_SUCCESS</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaacf52f132faf29b473cdda6061f0f44a">CUDA_ERROR_DEINITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaa8feb999f0af99b4a25ab26b3866f4df8">CUDA_ERROR_NOT_INITIALIZED</a>, <a class="el" href="group__CUDA__TYPES.html#gga0cdead942fd5028d157641eef6bdeeaaaa484e9af32c1e9893ff21f0e0191a12d">CUDA_ERROR_INVALID_CONTEXT</a> \notefnerr</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="group__CUDA__CTX.html#ga37d9aab8410a94abcfa60a8f19a9d48f" title="Create a CUDA context.">cuCtxCreate</a>, <a class="el" href="group__CUDA__CTX.html#ga371ec2a7d64ebe39e198eeb0b1146c4e" title="Destroy a CUDA context.">cuCtxDestroy</a>, <a class="el" href="group__CUDA__CTX.html#gaba93fa1c4a4f3da76d87704716a3d3c0" title="Gets the context&#39;s API version.">cuCtxGetApiVersion</a>, <a class="el" href="group__CUDA__CTX.html#gab144ce4581a0bf7cd362659776534a84" title="Returns the preferred cache configuration for the current context.">cuCtxGetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#gafe15c5d23b83550e31858899b081b4c3" title="Returns the device ID for the current context.">cuCtxGetDevice</a>, <a class="el" href="group__CUDA__CTX.html#ga36193dc05dde46af588434abdc4f0714" title="Returns the flags for the current context.">cuCtxGetFlags</a>, <a class="el" href="group__CUDA__CTX.html#gaab10bd874e0bf40a2989443ad42ed428" title="Returns resource limits.">cuCtxGetLimit</a>, <a class="el" href="group__CUDA__CTX.html#gab98ae0f3b858744645de0be934c12196" title="Pops the current CUDA context from the current CPU thread.">cuCtxPopCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga8e80640a19cf279cd06df1022f12877d" title="Pushes a context on the current CPU thread.">cuCtxPushCurrent</a>, <a class="el" href="group__CUDA__CTX.html#ga138e543965e8c57c652100a3a0fdecd9" title="Sets the preferred cache configuration for the current context.">cuCtxSetCacheConfig</a>, <a class="el" href="group__CUDA__CTX.html#ga4629158e32b781e675573ea7c2c4dd17" title="Set resource limits.">cuCtxSetLimit</a>, <a class="el" href="cuda__runtime__api_8cc.html#ab10bcf7183e1f78e0f5cac0672e0e4a1">cudaDeviceSynchronize</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="cuda__runtime__api_8cc_source.html#l04323">4323</a> of file <a class="el" href="cuda__runtime__api_8cc_source.html">cuda_runtime_api.cc</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
